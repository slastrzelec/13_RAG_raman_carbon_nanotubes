{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab9bc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba plik√≥w PDF w raw: 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Characterization of carbon nanotube filters and other carbonaceous materials by Raman spectroscopy‚ÄîII study on dispersion and disorder parameters.pdf',\n",
       " 'Jorio_2003_New_J._Phys._5_139.pdf',\n",
       " 'PhysRevB.61.14095_b_wazna.pdf',\n",
       " 'por√≥wnaine dwa lasery.pdf',\n",
       " 'R1.pdf']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üì¶ Importy\n",
    "import os\n",
    "import fitz  # pymupdf\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# üóÇÔ∏è ≈öcie≈ºki do folder√≥w\n",
    "RAW_DIR = \"../data/raw\"\n",
    "PROCESSED_DIR = \"../data/processed\"\n",
    "\n",
    "# üìå Sprawdzenie, czy foldery istniejƒÖ\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# ‚úÖ PodglƒÖd plik√≥w w raw\n",
    "pdf_files = [f for f in os.listdir(RAW_DIR) if f.lower().endswith(\".pdf\")]\n",
    "print(f\"Liczba plik√≥w PDF w raw: {len(pdf_files)}\")\n",
    "pdf_files[:5]  # poka≈º pierwsze 5 plik√≥w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d349b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba plik√≥w PDF w raw: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing PDFs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:02<00:00,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF-y wczytane i zapisane jako JSON + metadata CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Import tqdm (zwyk≈Çy, nie notebook)\n",
    "from tqdm import tqdm\n",
    "import fitz  # pymupdf\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# üìÇ ≈öcie≈ºki (te same co w pierwszej kom√≥rce)\n",
    "RAW_DIR = \"../data/raw\"\n",
    "PROCESSED_DIR = \"../data/processed\"\n",
    "\n",
    "# ‚úÖ Upewniamy siƒô, ≈ºe folder processed istnieje\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Lista plik√≥w PDF\n",
    "pdf_files = [f for f in os.listdir(RAW_DIR) if f.lower().endswith(\".pdf\")]\n",
    "print(f\"Liczba plik√≥w PDF w raw: {len(pdf_files)}\")\n",
    "pdf_files[:5]  # podglƒÖd pierwszych 5 plik√≥w\n",
    "\n",
    "# Lista do przechowywania metadanych\n",
    "metadata_list = []\n",
    "\n",
    "# Iteracja po PDF-ach\n",
    "for pdf_file in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "    pdf_path = os.path.join(RAW_DIR, pdf_file)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # WyciƒÖganie tekstu ze stron\n",
    "    pages_text = [doc[page_num].get_text() for page_num in range(len(doc))]\n",
    "    \n",
    "    # Metadata\n",
    "    metadata = {\n",
    "        \"filename\": pdf_file,\n",
    "        \"num_pages\": len(doc),\n",
    "        \"text\": pages_text\n",
    "    }\n",
    "    metadata_list.append(metadata)\n",
    "    \n",
    "    # Zapis JSON dla ka≈ºdego PDF\n",
    "    json_path = os.path.join(PROCESSED_DIR, pdf_file.replace(\".pdf\", \".json\"))\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Zapis zbiorczy metadata CSV\n",
    "df_metadata = pd.DataFrame([{\"filename\": m[\"filename\"], \"num_pages\": m[\"num_pages\"]} for m in metadata_list])\n",
    "df_metadata.to_csv(os.path.join(PROCESSED_DIR, \"metadata.csv\"), index=False)\n",
    "\n",
    "print(\"‚úÖ PDF-y wczytane i zapisane jako JSON + metadata CSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06157219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunking PDFs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27/27 [00:00<00:00, 852.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chunking zako≈Ñczony! Liczba chunk√≥w: 3443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Parametry chunkingu\n",
    "CHUNK_SIZE = 500    # liczba znak√≥w na chunk\n",
    "OVERLAP = 100       # liczba znak√≥w nak≈Çadki miƒôdzy chunkami\n",
    "\n",
    "# Wczytanie wczytanych JSON-√≥w\n",
    "pdf_json_files = [f for f in os.listdir(PROCESSED_DIR) if f.lower().endswith(\".json\") and f != \"chunks.json\"]\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "for pdf_file in tqdm(pdf_json_files, desc=\"Chunking PDFs\"):\n",
    "    json_path = os.path.join(PROCESSED_DIR, pdf_file)\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    filename = data[\"filename\"]\n",
    "    text_pages = data[\"text\"]\n",
    "    \n",
    "    # ≈ÅƒÖczymy wszystkie strony w jeden tekst\n",
    "    full_text = \"\\n\".join(text_pages)\n",
    "    \n",
    "    # Chunkowanie\n",
    "    start = 0\n",
    "    text_length = len(full_text)\n",
    "    while start < text_length:\n",
    "        end = min(start + CHUNK_SIZE, text_length)\n",
    "        chunk_text = full_text[start:end]\n",
    "        \n",
    "        all_chunks.append({\n",
    "            \"filename\": filename,\n",
    "            \"chunk_start\": start,\n",
    "            \"chunk_end\": end,\n",
    "            \"text\": chunk_text\n",
    "        })\n",
    "        \n",
    "        start += CHUNK_SIZE - OVERLAP\n",
    "\n",
    "# Zapis wszystkich chunk√≥w do JSON\n",
    "chunks_path = os.path.join(PROCESSED_DIR, \"chunks.json\")\n",
    "with open(chunks_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Chunking zako≈Ñczony! Liczba chunk√≥w: {len(all_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa91e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\slast\\miniconda3\\envs\\13_RAG\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Exception ignored in: <function tqdm.__del__ at 0x00000262EE69CE50>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\slast\\miniconda3\\envs\\13_RAG\\lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\slast\\miniconda3\\envs\\13_RAG\\lib\\site-packages\\tqdm\\notebook.py\", line 277, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba chunk√≥w do embeddingu: 3443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\slast\\miniconda3\\envs\\13_RAG\\lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\slast\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 392.50it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54/54 [01:32<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS index utworzony. Liczba wektor√≥w w indexie: 3443\n",
      "‚úÖ Embeddings i FAISS index zapisane w data/processed/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Parametry\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"  # szybki, lekki model\n",
    "EMBEDDING_DIM = 384              # wymiar dla all-MiniLM-L6-v2\n",
    "\n",
    "# üîπ Wczytanie chunk√≥w\n",
    "chunks_path = os.path.join(PROCESSED_DIR, \"chunks.json\")\n",
    "with open(chunks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "print(f\"Liczba chunk√≥w do embeddingu: {len(chunks)}\")\n",
    "\n",
    "# üîπ Utworzenie modelu embedding√≥w\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# üîπ Tworzenie embeddings\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "embeddings = model.encode(texts, show_progress_bar=True, batch_size=64)\n",
    "embeddings = np.array(embeddings).astype(\"float32\")\n",
    "\n",
    "# üîπ Tworzenie FAISS index\n",
    "index = faiss.IndexFlatL2(EMBEDDING_DIM)  # L2 distance\n",
    "index.add(embeddings)\n",
    "print(f\"‚úÖ FAISS index utworzony. Liczba wektor√≥w w indexie: {index.ntotal}\")\n",
    "\n",
    "# üîπ Zapis FAISS index na dysku\n",
    "faiss.write_index(index, os.path.join(PROCESSED_DIR, \"faiss_index.index\"))\n",
    "\n",
    "# üîπ Zapis chunks metadata (do retrieval)\n",
    "chunks_meta_path = os.path.join(PROCESSED_DIR, \"chunks_meta.json\")\n",
    "with open(chunks_meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"‚úÖ Embeddings i FAISS index zapisane w data/processed/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "947f2cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 194.99it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RANK 1 | File: R12.pdf | Distance: 0.2040 ---\n",
      "\n",
      "of Raman scattering\n",
      "processes relevant to carbon nanotubes are reviewed, and the theoretical foundations for these topics are presented.\n",
      "The most common experimental techniques used to probe carbon nanotubes are summarized, followed by a review of\n",
      "the novel experimental Ô¨Åndings for each of the features in the Ô¨Årst order and second order Raman spectra for single\n",
      "wall carbon nanotubes. These results are presented and discussed in connection with theoretical considerations.\n",
      "Raman spectra for bundle ...\n",
      "\n",
      "--- RANK 2 | File: Raman spectroscopy of carbon nanotubes.pdf | Distance: 0.2040 ---\n",
      "\n",
      "of Raman scattering\n",
      "processes relevant to carbon nanotubes are reviewed, and the theoretical foundations for these topics are presented.\n",
      "The most common experimental techniques used to probe carbon nanotubes are summarized, followed by a review of\n",
      "the novel experimental Ô¨Åndings for each of the features in the Ô¨Årst order and second order Raman spectra for single\n",
      "wall carbon nanotubes. These results are presented and discussed in connection with theoretical considerations.\n",
      "Raman spectra for bundle ...\n",
      "\n",
      "--- RANK 3 | File: R12.pdf | Distance: 0.2106 ---\n",
      "\n",
      "n the nanotube diameter and chirality, we can evaluate and\n",
      "characterize a given nanotube sample in some detail by resonance Raman spectroscopy.\n",
      "In the following sections, we brieÔ¨Çy review the many Raman features observed in the Raman spectra\n",
      "of carbon nanotubes, addressing the carbon nanotube physics that can be learned from their Raman\n",
      "spectra. In Section 5.1 a very brief coverage of the synthesis of carbon nanotubes is given and how\n",
      "Raman spectroscopy can be used for characterization purposes, ...\n",
      "\n",
      "--- RANK 4 | File: Raman spectroscopy of carbon nanotubes.pdf | Distance: 0.2106 ---\n",
      "\n",
      "n the nanotube diameter and chirality, we can evaluate and\n",
      "characterize a given nanotube sample in some detail by resonance Raman spectroscopy.\n",
      "In the following sections, we brieÔ¨Çy review the many Raman features observed in the Raman spectra\n",
      "of carbon nanotubes, addressing the carbon nanotube physics that can be learned from their Raman\n",
      "spectra. In Section 5.1 a very brief coverage of the synthesis of carbon nanotubes is given and how\n",
      "Raman spectroscopy can be used for characterization purposes, ...\n",
      "\n",
      "--- RANK 5 | File: R11 Jorio_2003_New_J._Phys._5_139.pdf | Distance: 0.2162 ---\n",
      "\n",
      "nal remarks\n",
      "15\n",
      "Acknowledgments\n",
      "15\n",
      "References\n",
      "16\n",
      "1. Introduction\n",
      "This review is aimed at researchers and engineers who are not experts in Raman spectroscopy,\n",
      "but want to use this technique as an easy and quick characterization tool for carbon nanotube\n",
      "samples. The Raman spectra from carbon nanotubes are rich in information about the structure\n",
      "and properties of nanotubes and the present review should provide a guide for people wanting to\n",
      "understand questions such as: What is the radial breathing m ...\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# üîπ Parametry\n",
    "TOP_K = 5  # ile najbardziej podobnych chunk√≥w\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "EMBEDDING_DIM = 384\n",
    "\n",
    "# üîπ Wczytanie FAISS index\n",
    "index_path = \"../data/processed/faiss_index.index\"\n",
    "index = faiss.read_index(index_path)\n",
    "\n",
    "# üîπ Wczytanie metadata chunk√≥w\n",
    "with open(\"../data/processed/chunks_meta.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks_meta = json.load(f)\n",
    "\n",
    "# üîπ Model embedding√≥w\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# üîπ Funkcja do zapytania\n",
    "def retrieve(query, top_k=TOP_K):\n",
    "    query_embedding = model.encode([query]).astype(\"float32\")\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        chunk_info = chunks_meta[idx]\n",
    "        results.append({\n",
    "            \"rank\": i+1,\n",
    "            \"filename\": chunk_info[\"filename\"],\n",
    "            \"chunk_start\": chunk_info[\"chunk_start\"],\n",
    "            \"chunk_end\": chunk_info[\"chunk_end\"],\n",
    "            \"text\": chunk_info[\"text\"],\n",
    "            \"distance\": float(distances[0][i])\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# üîπ Przyk≈Çadowe zapytanie\n",
    "query = \"Raman spectroscopy of carbon nanotubes\"\n",
    "results = retrieve(query)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"\\n--- RANK {r['rank']} | File: {r['filename']} | Distance: {r['distance']:.4f} ---\\n\")\n",
    "    print(r[\"text\"][:500], \"...\")  # poka≈º pierwsze 500 znak√≥w chunka\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9859436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raman spectroscopy jest jednƒÖ z najskuteczniejszych technik do analizy nanorurek wƒôglowych (SWNT - single-walled carbon nanotubes) ze wzglƒôdu na jej zdolno≈õƒá do dostarczania informacji o ich strukturze, w≈Ça≈õciwo≈õciach elektronicznych oraz dynamice. Oto kluczowe aspekty, kt√≥re wyja≈õniajƒÖ, jak Raman spectroscopy umo≈ºliwia okre≈õlenie w≈Ça≈õciwo≈õci nanorurek wƒôglowych:\n",
      "\n",
      "### 1. **Charakterystyka spektralna**\n",
      "Raman spectroscopy pozwala na identyfikacjƒô charakterystycznych pasm (band), takich jak:\n",
      "- **D (Disorder) band**: zwiƒÖzane z defektami w strukturze wƒôglowej, co pozwala na ocenƒô poziomu nieuporzƒÖdkowania w nanorurkach.\n",
      "- **G band**: odpowiada za akustyczne oraz optyczne plastyczne wzbudzenia (phonons) w sieci wƒôglowej i jest u≈ºytecznym wska≈∫nikiem stanu materia≈Çu.\n",
      "- **RBM (Radial Breathing Mode)**: pasmo to jest szczeg√≥lnie wra≈ºliwe na ≈õrednicƒô nanorurek wƒôglowych. Przesuniƒôcia czƒôsto≈õci RBM sƒÖ zwiƒÖzane bezpo≈õrednio z (n, m) chiralno≈õciƒÖ nanorurek, co umo≈ºliwia ich klasyfikacjƒô.\n",
      "\n",
      "### 2. **Ocena struktury chirpystycznej**\n",
      "Dziƒôki analizie intensywno≈õci i pozycji pasm D i G mo≈ºna okre≈õliƒá chiralno≈õƒá oraz ≈õrednicƒô nanorurek. Wskazania te sƒÖ szczeg√≥lnie cenne, poniewa≈º chiralno≈õƒá wp≈Çywa na w≈Ça≈õciwo≈õci elektronowe i optyczne nanorurek.\n",
      "\n",
      "### 3. **Analiza poziom√≥w defekt√≥w**\n",
      "Wsp√≥≈Çczynnik intensywno≈õci pasma D do pasma G (I_D/I_G) mo≈ºe byƒá u≈ºywany do oceny poziomu defekt√≥w w nanorurkach. Wysoki stosunek I_D/I_G wskazuje na wiƒôkszƒÖ ilo≈õƒá defekt√≥w, co ma istotne znaczenie dla w≈Ça≈õciwo≈õci mechanicznych i elektronicznych materia≈Çu.\n",
      "\n",
      "### 4. **Zale≈ºno≈õƒá od obszaru z pomiarem**\n",
      "Na w≈Ça≈õciwo≈õci uzyskane w Ramanie\n"
     ]
    }
   ],
   "source": [
    "# üîπ Za≈Çaduj .env\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()  # automatycznie szuka pliku .env w katalogu roboczym\n",
    "\n",
    "# üîπ Sprawdzenie klucza\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    raise ValueError(\"Nie znaleziono OPENAI_API_KEY w zmiennych ≈õrodowiskowych!\")\n",
    "\n",
    "# üîπ Import OpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "# üîπ Utworzenie klienta\n",
    "client = OpenAI()  # bierze klucz z os.environ\n",
    "\n",
    "# üîπ Funkcja RAG\n",
    "def rag_query(query, top_k=5):\n",
    "    # 1Ô∏è‚É£ Retrieve z FAISS\n",
    "    retrieved_chunks = retrieve(query, top_k=top_k)\n",
    "    \n",
    "    # 2Ô∏è‚É£ Po≈ÇƒÖcz teksty w kontekst\n",
    "    context = \"\\n\\n\".join([c[\"text\"] for c in retrieved_chunks])\n",
    "    \n",
    "    # 3Ô∏è‚É£ Przygotowanie promptu\n",
    "    prompt = f\"Masz dostƒôp do nastƒôpujƒÖcych fragment√≥w publikacji naukowych:\\n\\n{context}\\n\\nOdpowiedz wyczerpujƒÖco na pytanie: {query}\"\n",
    "    \n",
    "    # 4Ô∏è‚É£ Wywo≈Çanie LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Jeste≈õ ekspertem w dziedzinie spektroskopii Ramana i nanostruktur wƒôglowych.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# üîπ Przyk≈Çad zapytania\n",
    "query = \"Jak Raman spectroscopy pozwala okre≈õliƒá w≈Ça≈õciwo≈õci nanorurek wƒôglowych?\"\n",
    "answer = rag_query(query)\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "13_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
